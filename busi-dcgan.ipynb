{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2021025,"sourceType":"datasetVersion","datasetId":1209633}],"dockerImageVersionId":23025,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport cv2\n\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import regularizers, layers, Model, Sequential\n\nfrom collections import defaultdict\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-02T13:58:44.100932Z","iopub.execute_input":"2024-04-02T13:58:44.101208Z","iopub.status.idle":"2024-04-02T13:58:45.788822Z","shell.execute_reply.started":"2024-04-02T13:58:44.10116Z","shell.execute_reply":"2024-04-02T13:58:45.788034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = 224\ndataset_paths = [\n    '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n]\n\ndata_dict = defaultdict(list)\nerror_count = 0\nimage_paths = []\nimages = []\nlabels = []\nmasks = []\n\nlimit = 1000\n\nfor path in dataset_paths:\n    for dirpath, _, filenames in os.walk(path):\n        for filename in tqdm(filenames):\n            \n            if 'mask' in filename: continue\n            label = dirpath.split('/')[-1]\n            if len(data_dict[label]) >= limit: continue\n            try:\n                path = os.path.join(dirpath, filename)\n                image = cv2.imread(path) # Check for no error\n                image = cv2.resize(image, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                data_dict[label].append(image)\n                image_paths.append(path)\n                images.append(image)\n                labels.append(label)\n            except:\n#                 print('ERROR: ', filename)\n                error_count += 1\n\nprint(\"ErrorCount:\", error_count)\nprint(\"Total Images:\", len(images))","metadata":{"_uuid":"185d98f0f9b183a6daa29e9c40c8865d0e981458","_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-02T13:58:45.790069Z","iopub.execute_input":"2024-04-02T13:58:45.790379Z","iopub.status.idle":"2024-04-02T13:59:03.122429Z","shell.execute_reply.started":"2024-04-02T13:58:45.790323Z","shell.execute_reply":"2024-04-02T13:59:03.121654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"plt.rcParams.update({'font.size': 14})\nplt.figure(figsize=(12, 8))\nsns.barplot(x=list(data_dict.keys()), y=list(map(len, data_dict.values())))\nplt.title(\"Distribution of BUSI data\")","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:03.123952Z","iopub.execute_input":"2024-04-02T13:59:03.124214Z","iopub.status.idle":"2024-04-02T13:59:03.519847Z","shell.execute_reply.started":"2024-04-02T13:59:03.124162Z","shell.execute_reply":"2024-04-02T13:59:03.518851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = list(data_dict.keys())\nnum_classes = len(classes)\nclasses","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:03.521475Z","iopub.execute_input":"2024-04-02T13:59:03.522053Z","iopub.status.idle":"2024-04-02T13:59:03.528527Z","shell.execute_reply.started":"2024-04-02T13:59:03.521988Z","shell.execute_reply":"2024-04-02T13:59:03.527893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert labels to numpy array\nx = np.stack(images, axis=0) / 255.0\ny = np.array([classes.index(label) for label in labels])\n\nx.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:03.529647Z","iopub.execute_input":"2024-04-02T13:59:03.529982Z","iopub.status.idle":"2024-04-02T13:59:04.288213Z","shell.execute_reply.started":"2024-04-02T13:59:03.529947Z","shell.execute_reply":"2024-04-02T13:59:04.287232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define some parameters","metadata":{}},{"cell_type":"code","source":"# Input shape\nchannels = 3\n\nimg_shape = (IMG_SIZE, IMG_SIZE, channels)        \nlatent_dim = 100\n\nnum_target = 1350\ngen_batch = 40","metadata":{"_uuid":"6bbe97e46cc97644e5fa3e1aaf7207456705ce48","execution":{"iopub.status.busy":"2024-04-02T13:59:04.289662Z","iopub.execute_input":"2024-04-02T13:59:04.290172Z","iopub.status.idle":"2024-04-02T13:59:04.29451Z","shell.execute_reply.started":"2024-04-02T13:59:04.289931Z","shell.execute_reply":"2024-04-02T13:59:04.293816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define models","metadata":{}},{"cell_type":"code","source":"def build_generator(img_size=IMG_SIZE, num_blocks=4):\n\n    model = Sequential()\n    \n    k = 2 ** (num_blocks)\n    depth = 2 ** (3 + num_blocks)\n    w = h = img_size // k\n    \n    # Fully Connected Layers\n    model.add(layers.Dense(w * h * depth, input_shape=(latent_dim, ), activation=\"relu\"))\n    model.add(layers.Reshape((w, h, depth))) # img_size / k\n    \n    for i in range(num_blocks):\n\n        model.add(layers.UpSampling2D()) #upsamples to img_size to \n        model.add(layers.Conv2D(depth, kernel_size=3, padding=\"same\"))\n        model.add(layers.BatchNormalization(momentum=0.8))\n        model.add(layers.Activation(\"relu\"))\n    \n    model.add(layers.Conv2D(channels, kernel_size=3, padding=\"same\"))\n    model.add(layers.Activation(\"sigmoid\"))\n    \n    model.summary()\n    \n    #outputs an image\n    noise = layers.Input(shape=(latent_dim, ))\n    img = model(noise)\n\n    return Model(noise, img)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:04.29593Z","iopub.execute_input":"2024-04-02T13:59:04.29619Z","iopub.status.idle":"2024-04-02T13:59:04.309557Z","shell.execute_reply.started":"2024-04-02T13:59:04.29614Z","shell.execute_reply":"2024-04-02T13:59:04.308965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_discriminator():\n\n    model = Sequential()\n    \n    model.add(layers.Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding='same'))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.Dropout(0.25))\n    #no normalization for the first layer\n\n    model.add(layers.Conv2D(64, kernel_size=3, strides=2, padding='same'))\n    model.add(layers.BatchNormalization(momentum=0.8))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.Dropout(0.25))\n\n    model.add(layers.Conv2D(128, kernel_size=3, strides=2, padding='same'))\n    model.add(layers.BatchNormalization(momentum=0.8))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.Dropout(0.25))\n\n    model.add(layers.Conv2D(256, kernel_size=3, strides=2, padding='same'))\n    model.add(layers.BatchNormalization(momentum=0.8))\n    model.add(layers.LeakyReLU(alpha=0.2))\n    model.add(layers.Dropout(0.25))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1, activation='sigmoid'))\n    \n    model.summary()\n    \n    img = layers.Input(shape=img_shape)\n    validity = model(img)\n\n    return Model(img, validity)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:04.31076Z","iopub.execute_input":"2024-04-02T13:59:04.311014Z","iopub.status.idle":"2024-04-02T13:59:04.320652Z","shell.execute_reply.started":"2024-04-02T13:59:04.310972Z","shell.execute_reply":"2024-04-02T13:59:04.320009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define helper functions","metadata":{}},{"cell_type":"code","source":"def show_imgs():\n    \n    r, c = 3, 3\n    noise = np.random.normal(0, 1, (r * c, latent_dim))\n    gen_imgs = generator.predict(noise)\n\n    fig, axs = plt.subplots(r, c, figsize=(12, 12))\n    cnt = 0\n    for i in range(r):\n        for j in range(c):\n            axs[i, j].imshow(gen_imgs[cnt])\n            axs[i, j].axis('off')\n            cnt += 1\n            \n    plt.show()\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:04.321846Z","iopub.execute_input":"2024-04-02T13:59:04.322078Z","iopub.status.idle":"2024-04-02T13:59:04.333936Z","shell.execute_reply.started":"2024-04-02T13:59:04.322031Z","shell.execute_reply":"2024-04-02T13:59:04.333212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_losses(losses):\n    plt.rcParams.update({'font.size': 14})\n    losses = np.array(losses)\n    fig, ax = plt.subplots(figsize=(15, 10))\n    plt.plot(losses.T[0], label='Discriminator')\n    plt.plot(losses.T[1], label='Generator')\n    plt.title(\"Training Losses\")\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:04.334924Z","iopub.execute_input":"2024-04-02T13:59:04.335167Z","iopub.status.idle":"2024-04-02T13:59:04.343637Z","shell.execute_reply.started":"2024-04-02T13:59:04.335118Z","shell.execute_reply":"2024-04-02T13:59:04.342966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFG","metadata":{}},{"cell_type":"code","source":"batch_size=16\nsteps = 6000\ndisplay_interval=1000\n\nvalid = np.ones((batch_size, 1))\nvalid += 0.05 * np.random.random(valid.shape) * (-1)\n\nfake = np.zeros((batch_size, 1))\nfake += 0.05 * np.random.random(fake.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:04.344849Z","iopub.execute_input":"2024-04-02T13:59:04.345152Z","iopub.status.idle":"2024-04-02T13:59:04.354156Z","shell.execute_reply.started":"2024-04-02T13:59:04.345077Z","shell.execute_reply":"2024-04-02T13:59:04.353409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GAN apply for Benign class","metadata":{}},{"cell_type":"code","source":"# x_idx = 0\n# X_train = x[y.flatten() == x_idx]\n# current_label = classes[x_idx]\n# current_label, X_train.shape","metadata":{"_uuid":"3c9d3f9cf2232a09ed3fd581079665dd3d8b43f0","execution":{"iopub.status.busy":"2024-04-02T13:59:04.355266Z","iopub.execute_input":"2024-04-02T13:59:04.355559Z","iopub.status.idle":"2024-04-02T13:59:04.367743Z","shell.execute_reply.started":"2024-04-02T13:59:04.355501Z","shell.execute_reply":"2024-04-02T13:59:04.366819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build the generator\n# generator = build_generator()\n# generator.summary()","metadata":{"_uuid":"9ed33576c717096c411619e435f29e9cdd3e357e","execution":{"iopub.status.busy":"2024-04-02T13:59:04.368864Z","iopub.execute_input":"2024-04-02T13:59:04.369068Z","iopub.status.idle":"2024-04-02T13:59:04.378038Z","shell.execute_reply.started":"2024-04-02T13:59:04.369032Z","shell.execute_reply":"2024-04-02T13:59:04.377244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build and compile the discriminator\n# discriminator = build_discriminator()\n# discriminator.summary()","metadata":{"_uuid":"935ab37657be696521f5d68d35adcf49708cebd6","execution":{"iopub.status.busy":"2024-04-02T13:59:04.379069Z","iopub.execute_input":"2024-04-02T13:59:04.379316Z","iopub.status.idle":"2024-04-02T13:59:04.387233Z","shell.execute_reply.started":"2024-04-02T13:59:04.379275Z","shell.execute_reply":"2024-04-02T13:59:04.386612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0002, 0.5), metrics=['accuracy'])\n# discriminator.trainable = False\n\n# # The generator takes noise as input and generates imgs\n# z = layers.Input(shape=(latent_dim, ))\n# img = generator(z)\n# # The discriminator takes generated images as input and determines validity\n# validator = discriminator(img)\n# # The combined model (stacked generator and discriminator)\n# # Trains the generator to fool the discriminator\n# combined = Model(z, validator)\n# combined.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0002, 0.5))\n# combined.summary()","metadata":{"_uuid":"dd90187426779c7917172289001bef483faaf3bf","execution":{"iopub.status.busy":"2024-04-02T13:59:04.388436Z","iopub.execute_input":"2024-04-02T13:59:04.388767Z","iopub.status.idle":"2024-04-02T13:59:04.397142Z","shell.execute_reply.started":"2024-04-02T13:59:04.388688Z","shell.execute_reply":"2024-04-02T13:59:04.396495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{"_uuid":"f32cbe76d3cff4bc9e5774d7251946cc1cdd52de"}},{"cell_type":"code","source":"# checkpoint = f\"{current_label}_best.h5\"\n# losses=[]\n\n# for step in range(steps):\n    \n#     #  Train Discriminator\n#     # Select a random half of images\n#     idx = np.random.randint(0, X_train.shape[0], batch_size)\n#     imgs = X_train[idx]\n\n#     # Sample noise and generate a batch of new images\n#     noise = np.random.normal(0, 1, (batch_size, latent_dim))\n#     gen_imgs = generator.predict(noise)\n    \n#     # Train the discriminator (real classified as ones and generated as zeros)\n#     d_loss_real, acc_real = discriminator.train_on_batch(imgs, valid)\n#     d_loss_fake, acc_fake = discriminator.train_on_batch(gen_imgs, fake)\n#     d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n    \n#     #  Train Generator\n#     # Train the generator (wants discriminator to mistake images as real)\n#     noise = np.random.normal(0, 1, (batch_size, latent_dim))\n#     g_loss_1 = combined.train_on_batch(noise, valid)\n#     noise = np.random.normal(0, 1, (batch_size, latent_dim))\n#     g_loss_2 = combined.train_on_batch(noise, valid)\n#     g_loss = np.add(g_loss_1, g_loss_2) * 0.5\n    \n#     gan_loss = np.add(d_loss, g_loss) * 0.5\n    \n#     # Plot the progress\n#     if step % display_interval == 0:\n#         losses.append((d_loss, g_loss))\n#         print(f\"GAN loss: {gan_loss}\")\n#         print(f\"D_loss_real: {d_loss_real}, d_loss_fake: {d_loss_fake}\")\n#         print(\"%d [D loss: %f] [G loss: %f]\" % (step, d_loss, g_loss))\n#         show_imgs()\n\n# generator.save(checkpoint)","metadata":{"_uuid":"d2ea0d853f1df7412107e57420d68d52f8d30054","execution":{"iopub.status.busy":"2024-04-02T13:59:04.398647Z","iopub.execute_input":"2024-04-02T13:59:04.398938Z","iopub.status.idle":"2024-04-02T13:59:04.407813Z","shell.execute_reply.started":"2024-04-02T13:59:04.398884Z","shell.execute_reply":"2024-04-02T13:59:04.4072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show_losses(losses)","metadata":{"_uuid":"5f9afa88b655a5d73e635673809f75cc482ea768","execution":{"iopub.status.busy":"2024-04-02T13:59:04.409038Z","iopub.execute_input":"2024-04-02T13:59:04.409314Z","iopub.status.idle":"2024-04-02T13:59:04.42148Z","shell.execute_reply.started":"2024-04-02T13:59:04.409264Z","shell.execute_reply":"2024-04-02T13:59:04.420635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generator = tf.keras.models.load_model(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:04.424621Z","iopub.execute_input":"2024-04-02T13:59:04.424866Z","iopub.status.idle":"2024-04-02T13:59:04.431378Z","shell.execute_reply.started":"2024-04-02T13:59:04.424813Z","shell.execute_reply":"2024-04-02T13:59:04.430536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# s = X_train[:40]\n# f, ax = plt.subplots(5,8, figsize=(16,10))\n# for i, img in enumerate(s):\n#         ax[i//8, i%8].imshow(img)\n#         ax[i//8, i%8].axis('off')\n        \n# plt.show()","metadata":{"_uuid":"2f5973ba4db11623609b11988bc3a49b54cdd0f9","execution":{"iopub.status.busy":"2024-04-02T13:59:04.432501Z","iopub.execute_input":"2024-04-02T13:59:04.432792Z","iopub.status.idle":"2024-04-02T13:59:04.44028Z","shell.execute_reply.started":"2024-04-02T13:59:04.432735Z","shell.execute_reply":"2024-04-02T13:59:04.439474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# noise = np.random.normal(size=(40, latent_dim))\n# generated_images = generator.predict(noise)\n# f, ax = plt.subplots(5,8, figsize=(16,10))\n# for i, img in enumerate(generated_images):\n#         ax[i//8, i%8].imshow(img)\n#         ax[i//8, i%8].axis('off')\n        \n# plt.show()","metadata":{"_uuid":"796d1b1025f88609b4a97412116ba239341a1c32","execution":{"iopub.status.busy":"2024-04-02T13:59:04.441237Z","iopub.execute_input":"2024-04-02T13:59:04.441475Z","iopub.status.idle":"2024-04-02T13:59:04.450535Z","shell.execute_reply.started":"2024-04-02T13:59:04.441424Z","shell.execute_reply":"2024-04-02T13:59:04.449667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num_gen = round((num_target - len(data_dict[current_label])) / gen_batch) * gen_batch\n# noise = np.random.normal(size=(num_gen, latent_dim))\n# gen_images = generator.predict(noise, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:04.451772Z","iopub.execute_input":"2024-04-02T13:59:04.452002Z","iopub.status.idle":"2024-04-02T13:59:04.464135Z","shell.execute_reply.started":"2024-04-02T13:59:04.451954Z","shell.execute_reply":"2024-04-02T13:59:04.463456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.makedirs(current_label, exist_ok=True)\n\n# for i, img in tqdm(enumerate(gen_images)):\n#     save_path = f\"{current_label}/gen_{i}.png\"\n#     plt.imsave(save_path, img)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:04.465971Z","iopub.execute_input":"2024-04-02T13:59:04.466292Z","iopub.status.idle":"2024-04-02T13:59:04.474349Z","shell.execute_reply.started":"2024-04-02T13:59:04.466223Z","shell.execute_reply":"2024-04-02T13:59:04.473668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GAN apply for Normal class","metadata":{}},{"cell_type":"code","source":"x_idx = 1\nX_train = x[y.flatten() == x_idx]\ncurrent_label = classes[x_idx]\ncurrent_label, X_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:04.475323Z","iopub.execute_input":"2024-04-02T13:59:04.475509Z","iopub.status.idle":"2024-04-02T13:59:04.609121Z","shell.execute_reply.started":"2024-04-02T13:59:04.475478Z","shell.execute_reply":"2024-04-02T13:59:04.608007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build the generator\ngenerator = build_generator()\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:04.610469Z","iopub.execute_input":"2024-04-02T13:59:04.610772Z","iopub.status.idle":"2024-04-02T13:59:05.293551Z","shell.execute_reply.started":"2024-04-02T13:59:04.610708Z","shell.execute_reply":"2024-04-02T13:59:05.292771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build and compile the discriminator\ndiscriminator = build_discriminator()\ndiscriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:05.29459Z","iopub.execute_input":"2024-04-02T13:59:05.294805Z","iopub.status.idle":"2024-04-02T13:59:05.830082Z","shell.execute_reply.started":"2024-04-02T13:59:05.294766Z","shell.execute_reply":"2024-04-02T13:59:05.829421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0002, 0.5), metrics=['accuracy'])\ndiscriminator.trainable = False\n\n# The generator takes noise as input and generates imgs\nz = layers.Input(shape=(latent_dim, ))\nimg = generator(z)\n# The discriminator takes generated images as input and determines validity\nvalidator = discriminator(img)\n# The combined model (stacked generator and discriminator)\n# Trains the generator to fool the discriminator\ncombined = Model(z, validator)\ncombined.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0002, 0.5))\ncombined.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:05.831275Z","iopub.execute_input":"2024-04-02T13:59:05.831484Z","iopub.status.idle":"2024-04-02T13:59:06.510997Z","shell.execute_reply.started":"2024-04-02T13:59:05.831446Z","shell.execute_reply":"2024-04-02T13:59:06.510292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"checkpoint = f\"{current_label}_best.h5\"\nlosses=[]\n\nfor step in range(steps):\n    \n    #  Train Discriminator\n    # Select a random half of images\n    idx = np.random.randint(0, X_train.shape[0], batch_size)\n    imgs = X_train[idx]\n\n    # Sample noise and generate a batch of new images\n    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n    gen_imgs = generator.predict(noise)\n    \n    # Train the discriminator (real classified as ones and generated as zeros)\n    d_loss_real, acc_real = discriminator.train_on_batch(imgs, valid)\n    d_loss_fake, acc_fake = discriminator.train_on_batch(gen_imgs, fake)\n    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n    \n    #  Train Generator\n    # Train the generator (wants discriminator to mistake images as real)\n    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n    g_loss_1 = combined.train_on_batch(noise, valid)\n    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n    g_loss_2 = combined.train_on_batch(noise, valid)\n    g_loss = np.add(g_loss_1, g_loss_2) * 0.5\n    \n    gan_loss = np.add(d_loss, g_loss) * 0.5\n    \n    # Plot the progress\n    if step % display_interval == 0:\n        losses.append((d_loss, g_loss))\n        print(f\"GAN loss: {gan_loss}\")\n        print(f\"D_loss_real: {d_loss_real}, d_loss_fake: {d_loss_fake}\")\n        print(\"%d [D loss: %f] [G loss: %f]\" % (step, d_loss, g_loss))\n        show_imgs()\n\ngenerator.save(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:59:06.512212Z","iopub.execute_input":"2024-04-02T13:59:06.512431Z","iopub.status.idle":"2024-04-02T15:01:03.167125Z","shell.execute_reply.started":"2024-04-02T13:59:06.512391Z","shell.execute_reply":"2024-04-02T15:01:03.166354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generator = tf.keras.models.load_model(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:01:03.168495Z","iopub.execute_input":"2024-04-02T15:01:03.168804Z","iopub.status.idle":"2024-04-02T15:01:03.172444Z","shell.execute_reply.started":"2024-04-02T15:01:03.168748Z","shell.execute_reply":"2024-04-02T15:01:03.171652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = X_train[:40]\nf, ax = plt.subplots(5,8, figsize=(16,10))\nfor i, img in enumerate(s):\n        ax[i//8, i%8].imshow(img)\n        ax[i//8, i%8].axis('off')\n        \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:01:03.173667Z","iopub.execute_input":"2024-04-02T15:01:03.17396Z","iopub.status.idle":"2024-04-02T15:01:05.041713Z","shell.execute_reply.started":"2024-04-02T15:01:03.173906Z","shell.execute_reply":"2024-04-02T15:01:05.041063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise = np.random.normal(size=(40, latent_dim))\ngenerated_images = generator.predict(noise)\nf, ax = plt.subplots(5,8, figsize=(16,10))\nfor i, img in enumerate(generated_images):\n        ax[i//8, i%8].imshow(img)\n        ax[i//8, i%8].axis('off')\n        \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:01:05.0429Z","iopub.execute_input":"2024-04-02T15:01:05.043182Z","iopub.status.idle":"2024-04-02T15:01:07.929625Z","shell.execute_reply.started":"2024-04-02T15:01:05.04313Z","shell.execute_reply":"2024-04-02T15:01:07.928659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_gen = round((num_target - len(data_dict[current_label])) / gen_batch) * gen_batch\nnoise = np.random.normal(size=(num_gen, latent_dim))\ngen_images = generator.predict(noise, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:01:07.930922Z","iopub.execute_input":"2024-04-02T15:01:07.931207Z","iopub.status.idle":"2024-04-02T15:01:11.461461Z","shell.execute_reply.started":"2024-04-02T15:01:07.931155Z","shell.execute_reply":"2024-04-02T15:01:11.460759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(current_label, exist_ok=True)\n\nfor i, img in tqdm(enumerate(gen_images)):\n    save_path = f\"{current_label}/gen_{i}.png\"\n    plt.imsave(save_path, img)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:01:11.462905Z","iopub.execute_input":"2024-04-02T15:01:11.463244Z","iopub.status.idle":"2024-04-02T15:01:59.466873Z","shell.execute_reply.started":"2024-04-02T15:01:11.463184Z","shell.execute_reply":"2024-04-02T15:01:59.466168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GAN apply for Malignant class","metadata":{}},{"cell_type":"code","source":"x_idx = 2\nX_train = x[y.flatten() == x_idx]\ncurrent_label = classes[x_idx]\ncurrent_label, X_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:01:59.467948Z","iopub.execute_input":"2024-04-02T15:01:59.468204Z","iopub.status.idle":"2024-04-02T15:01:59.648289Z","shell.execute_reply.started":"2024-04-02T15:01:59.468158Z","shell.execute_reply":"2024-04-02T15:01:59.64754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build the generator\ngenerator = build_generator()\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:01:59.649758Z","iopub.execute_input":"2024-04-02T15:01:59.650169Z","iopub.status.idle":"2024-04-02T15:02:00.227292Z","shell.execute_reply.started":"2024-04-02T15:01:59.650061Z","shell.execute_reply":"2024-04-02T15:02:00.226459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build and compile the discriminator\ndiscriminator = build_discriminator()\ndiscriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:02:00.22852Z","iopub.execute_input":"2024-04-02T15:02:00.228776Z","iopub.status.idle":"2024-04-02T15:02:00.780345Z","shell.execute_reply.started":"2024-04-02T15:02:00.228725Z","shell.execute_reply":"2024-04-02T15:02:00.7794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0002, 0.5), metrics=['accuracy'])\ndiscriminator.trainable = False\n\n# The generator takes noise as input and generates imgs\nz = layers.Input(shape=(latent_dim, ))\nimg = generator(z)\n# The discriminator takes generated images as input and determines validity\nvalidator = discriminator(img)\n# The combined model (stacked generator and discriminator)\n# Trains the generator to fool the discriminator\ncombined = Model(z, validator)\ncombined.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0002, 0.5))\ncombined.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:02:00.781613Z","iopub.execute_input":"2024-04-02T15:02:00.781921Z","iopub.status.idle":"2024-04-02T15:02:01.560413Z","shell.execute_reply.started":"2024-04-02T15:02:00.781864Z","shell.execute_reply":"2024-04-02T15:02:01.559652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"checkpoint = f\"{current_label}_best.h5\"\nlosses=[]\n\nfor step in range(steps):\n    \n    #  Train Discriminator\n    # Select a random half of images\n    idx = np.random.randint(0, X_train.shape[0], batch_size)\n    imgs = X_train[idx]\n\n    # Sample noise and generate a batch of new images\n    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n    gen_imgs = generator.predict(noise)\n    \n    # Train the discriminator (real classified as ones and generated as zeros)\n    d_loss_real, acc_real = discriminator.train_on_batch(imgs, valid)\n    d_loss_fake, acc_fake = discriminator.train_on_batch(gen_imgs, fake)\n    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n    \n    #  Train Generator\n    # Train the generator (wants discriminator to mistake images as real)\n    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n    g_loss_1 = combined.train_on_batch(noise, valid)\n    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n    g_loss_2 = combined.train_on_batch(noise, valid)\n    g_loss = np.add(g_loss_1, g_loss_2) * 0.5\n    \n    gan_loss = np.add(d_loss, g_loss) * 0.5\n    \n    # Plot the progress\n    if step % display_interval == 0:\n        losses.append((d_loss, g_loss))\n        print(f\"GAN loss: {gan_loss}\")\n        print(f\"D_loss_real: {d_loss_real}, d_loss_fake: {d_loss_fake}\")\n        print(\"%d [D loss: %f] [G loss: %f]\" % (step, d_loss, g_loss))\n        show_imgs()\n\ngenerator.save(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T15:02:01.56164Z","iopub.execute_input":"2024-04-02T15:02:01.561855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_losses(losses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generator = tf.keras.models.load_model(checkpoint)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = X_train[:40]\nf, ax = plt.subplots(5,8, figsize=(16,10))\nfor i, img in enumerate(s):\n        ax[i//8, i%8].imshow(img)\n        ax[i//8, i%8].axis('off')\n        \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise = np.random.normal(size=(40, latent_dim))\ngenerated_images = generator.predict(noise)\nf, ax = plt.subplots(5,8, figsize=(16,10))\nfor i, img in enumerate(generated_images):\n        ax[i//8, i%8].imshow(img)\n        ax[i//8, i%8].axis('off')\n        \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_gen = round((num_target - len(data_dict[current_label])) / gen_batch) * gen_batch\nnoise = np.random.normal(size=(num_gen, latent_dim))\ngen_images = generator.predict(noise, batch_size=batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(current_label, exist_ok=True)\n\nfor i, img in tqdm(enumerate(gen_images)):\n    save_path = f\"{current_label}/gen_{i}.png\"\n    plt.imsave(save_path, img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}